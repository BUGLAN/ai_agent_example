#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•Agentæ¨¡å‹ - æ¨¡å—åŒ–è®¾è®¡
æä¾›æ›´æ¸…æ™°çš„æ¶æ„å’Œæ›´å¥½çš„æ‰©å±•æ€§
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
import re
from datetime import datetime

class AgentType(Enum):
    """Agentç±»å‹æšä¸¾"""
    TEXT_ANALYZER = "text_analyzer"
    CHAT_BOT = "chat_bot"
    DATA_PROCESSOR = "data_processor"

class ResponseStatus(Enum):
    """å“åº”çŠ¶æ€æšä¸¾"""
    SUCCESS = "success"
    ERROR = "error"
    PENDING = "pending"

@dataclass
class AgentMessage:
    """Agentæ¶ˆæ¯æ•°æ®ç»“æ„"""
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AgentResponse:
    """Agentå“åº”æ•°æ®ç»“æ„"""
    content: str
    status: ResponseStatus
    confidence: float = 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    suggestions: List[str] = field(default_factory=list)

class BaseAgent(ABC):
    """AgentåŸºç±»"""
    
    def __init__(self, agent_id: str, agent_type: AgentType):
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.conversation_history: List[AgentMessage] = []
        self.stats = {
            "total_requests": 0,
            "successful_responses": 0,
            "error_responses": 0,
            "start_time": datetime.now()
        }
    
    @abstractmethod
    async def process(self, message: AgentMessage) -> AgentResponse:
        """å¤„ç†æ¶ˆæ¯çš„æ ¸å¿ƒæ–¹æ³•"""
        pass
    
    def add_to_history(self, message: AgentMessage):
        """æ·»åŠ åˆ°å¯¹è¯å†å²"""
        self.conversation_history.append(message)
        if len(self.conversation_history) > 100:  # é™åˆ¶å†å²è®°å½•å¤§å°
            self.conversation_history.pop(0)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–Agentç»Ÿè®¡ä¿¡æ¯"""
        uptime = datetime.now() - self.stats["start_time"]
        success_rate = (
            self.stats["successful_responses"] / self.stats["total_requests"] * 100
            if self.stats["total_requests"] > 0 else 0
        )
        
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type.value,
            "total_requests": self.stats["total_requests"],
            "successful_responses": self.stats["successful_responses"],
            "error_responses": self.stats["error_responses"],
            "success_rate": round(success_rate, 2),
            "uptime_seconds": int(uptime.total_seconds()),
            "conversation_length": len(self.conversation_history)
        }

class TextCategory(Enum):
    """æ–‡æœ¬ç±»åˆ«æšä¸¾"""
    NOUN = "åè¯"
    IDIOM = "æˆè¯­"
    XIEHOUYU = "æ­‡åè¯­"
    REGULAR_SENTENCE = "å¸¸è§„å¥å­"
    QUESTION = "ç–‘é—®å¥"
    COMMAND = "å‘½ä»¤å¥"
    UNKNOWN = "æœªçŸ¥"

class SimpleTextAgent(BaseAgent):
    """ç®€å•çš„æ–‡æœ¬åˆ†æAgent"""
    
    def __init__(self, agent_id: str = "text_analyzer_001"):
        super().__init__(agent_id, AgentType.TEXT_ANALYZER)
        self._load_patterns()
    
    def _load_patterns(self):
        """åŠ è½½æ–‡æœ¬æ¨¡å¼"""
        self.patterns = {
            TextCategory.IDIOM: [
                "ä¸€å¿ƒä¸€æ„", "ä¸ƒä¸Šå…«ä¸‹", "äº”èŠ±å…«é—¨", "ä¹ç‰›ä¸€æ¯›", "åå…¨åç¾",
                "ç™¾å‘ç™¾ä¸­", "åƒå†›ä¸‡é©¬", "ä¸‡æ— ä¸€å¤±", "é£å’Œæ—¥ä¸½", "å…´é«˜é‡‡çƒˆ"
            ],
            TextCategory.XIEHOUYU: [
                "æ³¥è©è¨è¿‡æ²³", "å…«ä»™è¿‡æµ·", "ç«¹ç¯®æ‰“æ°´", "å¯¹ç‰›å¼¹ç´", "çŒ«å“­è€é¼ "
            ],
            TextCategory.NOUN: [
                "ç”µè„‘", "æ‰‹æœº", "æ±½è½¦", "æˆ¿å­", "å­¦æ ¡", "å…¬å¸", "æœ‹å‹", "å®¶äºº"
            ]
        }
        
        # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.regex_patterns = {
            TextCategory.QUESTION: r'.*\?|.*ï¼Ÿ|ä»€ä¹ˆ|æ€ä¹ˆ|ä¸ºä»€ä¹ˆ|å¦‚ä½•',
            TextCategory.COMMAND: r'è¯·|å¸®æˆ‘|ç»™æˆ‘|éœ€è¦|åº”è¯¥|å¿…é¡»'
        }
    
    async def process(self, message: AgentMessage) -> AgentResponse:
        """å¤„ç†æ–‡æœ¬åˆ†æè¯·æ±‚"""
        try:
            self.stats["total_requests"] += 1
            
            text = message.content.strip()
            if not text:
                response = AgentResponse(
                    content="è¾“å…¥ä¸ºç©º",
                    status=ResponseStatus.ERROR,
                    confidence=0.0,
                    suggestions=["è¯·è¾“å…¥ä¸€äº›æ–‡æœ¬è¿›è¡Œåˆ†æ"]
                )
                self.stats["error_responses"] += 1
                return response
            
            # åˆ†ææ–‡æœ¬
            category, confidence = self._analyze_text(text)
            suggestions = self._generate_suggestions(text, category)
            explanation = self._generate_explanation(text, category, confidence)
            
            response = AgentResponse(
                content=explanation,
                status=ResponseStatus.SUCCESS,
                confidence=confidence,
                metadata={
                    "original_text": text,
                    "category": category.value,
                    "text_length": len(text)
                },
                suggestions=suggestions
            )
            
            self.stats["successful_responses"] += 1
            self.add_to_history(message)
            return response
            
        except Exception as e:
            self.stats["error_responses"] += 1
            return AgentResponse(
                content=f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}",
                status=ResponseStatus.ERROR,
                confidence=0.0,
                suggestions=["è¯·ç¨åé‡è¯•", "æ£€æŸ¥è¾“å…¥å†…å®¹æ ¼å¼"]
            )
    
    def _analyze_text(self, text: str) -> Tuple[TextCategory, float]:
        """åˆ†ææ–‡æœ¬ç±»åˆ«"""
        text = text.strip()
        
        # æ£€æŸ¥æˆè¯­
        for idiom in self.patterns[TextCategory.IDIOM]:
            if idiom in text:
                return TextCategory.IDIOM, 0.95
        
        # æ£€æŸ¥æ­‡åè¯­
        for xiehouyu in self.patterns[TextCategory.XIEHOUYU]:
            if xiehouyu in text:
                return TextCategory.XIEHOUYU, 0.90
        
        # æ£€æŸ¥åè¯
        for noun in self.patterns[TextCategory.NOUN]:
            if noun in text:
                return TextCategory.NOUN, 0.85
        
        # æ£€æŸ¥ç–‘é—®å¥
        if re.search(self.regex_patterns[TextCategory.QUESTION], text, re.IGNORECASE):
            return TextCategory.QUESTION, 0.80
        
        # æ£€æŸ¥å‘½ä»¤å¥
        if re.search(self.regex_patterns[TextCategory.COMMAND], text, re.IGNORECASE):
            return TextCategory.COMMAND, 0.75
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸è§„å¥å­
        if len(text) > 5 and any(p in text for p in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š'):
            return TextCategory.REGULAR_SENTENCE, 0.70
        
        return TextCategory.UNKNOWN, 0.50
    
    def _generate_suggestions(self, text: str, category: TextCategory) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        suggestions_map = {
            TextCategory.IDIOM: [
                f"{text}çš„å‡ºå¤„å’Œå…¸æ•…",
                f"ä¸{text}æ„æ€ç›¸è¿‘çš„æˆè¯­",
                f"{text}çš„è‹±æ–‡ç¿»è¯‘"
            ],
            TextCategory.XIEHOUYU: [
                f"{text}çš„ä¸‹åŠå¥æ˜¯ä»€ä¹ˆï¼Ÿ",
                f"{text}çš„å¯“æ„å’Œå¯ç¤º",
                f"ç±»ä¼¼{text}çš„æ­‡åè¯­"
            ],
            TextCategory.NOUN: [
                f"å…³äº{text}çš„è¯¦ç»†ä»‹ç»",
                f"{text}çš„ç§ç±»å’Œåˆ†ç±»",
                f"å¦‚ä½•é€‰æ‹©åˆé€‚çš„{text}"
            ],
            TextCategory.QUESTION: [
                f"å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{text}",
                f"æ‰©å±•è¿™ä¸ªé—®é¢˜çš„èƒŒæ™¯",
                f"ç±»ä¼¼é—®é¢˜çš„è§£ç­”"
            ],
            TextCategory.COMMAND: [
                f"æ‰§è¡Œå‘½ä»¤ï¼š{text}",
                f"æä¾›å®Œæˆ{text}çš„æ­¥éª¤",
                f"{text}çš„æœ€ä½³å®è·µ"
            ],
            TextCategory.REGULAR_SENTENCE: [
                "è¿™å¥è¯å¯ä»¥å¦‚ä½•æ‰©å±•ï¼Ÿ",
                "ç±»ä¼¼è¡¨è¾¾çš„å¥å­",
                "å¦‚ä½•æ”¹å†™è¿™å¥è¯ä½¿å…¶æ›´ç”ŸåŠ¨"
            ],
            TextCategory.UNKNOWN: [
                "è¯·æä¾›æ›´å…·ä½“çš„æ–‡æœ¬",
                "å°è¯•è¾“å…¥æˆè¯­ã€åè¯æˆ–å¥å­",
                "æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹"
            ]
        }
        
        return suggestions_map.get(category, ["è¯·æä¾›æ›´å¤šä¿¡æ¯"])
    
    def _generate_explanation(self, text: str, category: TextCategory, confidence: float) -> str:
        """ç”Ÿæˆè§£é‡Š"""
        explanations = {
            TextCategory.IDIOM: f"'{text}'æ˜¯ä¸€ä¸ªå¸¸è§æˆè¯­ï¼Œé€šå¸¸ç”¨äºå½¢å®¹ç‰¹å®šçš„æƒ…å¢ƒæˆ–è¡¨è¾¾ç‰¹å®šçš„å«ä¹‰ã€‚",
            TextCategory.XIEHOUYU: f"'{text}'æ˜¯ä¸€ä¸ªæ­‡åè¯­çš„å‰åŠéƒ¨åˆ†ï¼Œé€šå¸¸åé¢è·Ÿç€å½¢è±¡çš„æ¯”å–»æˆ–åŒå…³è¯­ã€‚",
            TextCategory.NOUN: f"'{text}'æ˜¯ä¸€ä¸ªå…·ä½“åè¯ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ¢è®¨å…¶å±æ€§ã€ç‰¹å¾æˆ–ç›¸å…³è¯é¢˜ã€‚",
            TextCategory.QUESTION: f"è¿™æ˜¯ä¸€ä¸ªç–‘é—®å¥ï¼Œè¡¨è¾¾äº†æé—®è€…å¯¹'{text}'çš„ç–‘é—®æˆ–å¯»æ±‚ä¿¡æ¯ã€‚",
            TextCategory.COMMAND: f"è¿™æ˜¯ä¸€ä¸ªå‘½ä»¤æˆ–è¯·æ±‚ï¼Œè¡¨è¾¾äº†å¸Œæœ›'{text}'è¢«æ‰§è¡Œçš„æ„æ„¿ã€‚",
            TextCategory.REGULAR_SENTENCE: f"è¿™æ˜¯ä¸€ä¸ªåŒ…å«{len(text)}ä¸ªå­—ç¬¦çš„å¸¸è§„å¥å­ã€‚",
            TextCategory.UNKNOWN: f"æ— æ³•ç¡®å®š'{text}'çš„å…·ä½“ç±»åˆ«ï¼Œè¯·å°è¯•æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚"
        }
        
        base_explanation = explanations.get(category, "æ–‡æœ¬åˆ†æå®Œæˆ")
        return f"{base_explanation} (ç½®ä¿¡åº¦: {confidence:.1%})"

class AgentManager:
    """Agentç®¡ç†å™¨"""
    
    def __init__(self):
        self.agents: Dict[str, BaseAgent] = {}
        self._initialize_agents()
    
    def _initialize_agents(self):
        """åˆå§‹åŒ–æ‰€æœ‰Agent"""
        text_agent = SimpleTextAgent("main_text_analyzer")
        self.register_agent(text_agent)
    
    def register_agent(self, agent: BaseAgent):
        """æ³¨å†ŒAgent"""
        self.agents[agent.agent_id] = agent
    
    def get_agent(self, agent_id: str) -> Optional[BaseAgent]:
        """è·å–Agent"""
        return self.agents.get(agent_id)
    
    def list_agents(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰Agent"""
        return [
            {
                "agent_id": agent.agent_id,
                "agent_type": agent.agent_type.value,
                "stats": agent.get_stats()
            }
            for agent in self.agents.values()
        ]
    
    async def process_with_agent(self, agent_id: str, message: str) -> AgentResponse:
        """ä½¿ç”¨æŒ‡å®šAgentå¤„ç†æ¶ˆæ¯"""
        agent = self.get_agent(agent_id)
        if not agent:
            return AgentResponse(
                content=f"æœªæ‰¾åˆ°Agent: {agent_id}",
                status=ResponseStatus.ERROR,
                suggestions=["å¯ç”¨çš„Agent: " + ", ".join(self.agents.keys())]
            )
        
        agent_message = AgentMessage(content=message)
        return await agent.process(agent_message)

# å…¨å±€Agentç®¡ç†å™¨å®ä¾‹
agent_manager = AgentManager()

# ä¾¿æ·å‡½æ•°
async def analyze_text(text: str, agent_id: str = "main_text_analyzer") -> AgentResponse:
    """å¿«é€Ÿåˆ†ææ–‡æœ¬"""
    return await agent_manager.process_with_agent(agent_id, text)

def get_system_stats() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    return {
        "system": "ç®€å•Agentç³»ç»Ÿ",
        "version": "1.0.0",
        "agents": agent_manager.list_agents(),
        "timestamp": datetime.now().isoformat()
    }

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
async def demo():
    """æ¼”ç¤ºåŠŸèƒ½"""
    print("ğŸ¤– ç®€å•Agentç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # è·å–ç³»ç»Ÿä¿¡æ¯
    stats = get_system_stats()
    print(f"ç³»ç»Ÿç‰ˆæœ¬: {stats['version']}")
    print(f"å¯ç”¨Agent: {len(stats['agents'])}")
    
    # æµ‹è¯•æ–‡æœ¬åˆ†æ
    test_cases = [
        "ä¸€å¿ƒä¸€æ„",
        "æ³¥è©è¨è¿‡æ²³",
        "ç”µè„‘",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        "è¯·å¸®æˆ‘å®Œæˆè¿™ä¸ªä»»åŠ¡",
        "è¿™æ˜¯ä¸€ä¸ªæ™®é€šçš„å¥å­ã€‚"
    ]
    
    for text in test_cases:
        print(f"\nğŸ“ åˆ†æ: {text}")
        response = await analyze_text(text)
        print(f"ğŸ“Š ç±»åˆ«: {response.metadata.get('category', 'æœªçŸ¥')}")
        print(f"ğŸ’¡ å»ºè®®: {response.suggestions[0] if response.suggestions else 'æ— '}")
    
    print("\n" + "=" * 50)
    print("âœ… æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    import asyncio
    asyncio.run(demo())